{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import joblib\n",
    "from IPython.display import display\n",
    "\n",
    "# Load data\n",
    "data_path = 'data.xlsx'  # Update with your file path\n",
    "data = pd.read_excel(data_path)\n",
    "\n",
    "# Display the first few rows of the data\n",
    "display(data.head())\n",
    "\n",
    "# Select relevant features and the target variable\n",
    "features = [\n",
    "    'status_kemahasiswaan', 'pernah_ikut_mbmk', 'pernah_mbkm_apapun', \n",
    "    'performa_ipk', 'nilai_ipk', 'ikut_organisasi', 'jumlah_organisasi', \n",
    "    'scan_ktp', 'upload_sertifikat', 'upload_cv', 'upload_surat_rekomendasi'\n",
    "]\n",
    "target = 'lolos_mbkm'\n",
    "\n",
    "# Convert all values in the columns to strings to handle mixed types\n",
    "data[features] = data[features].astype(str)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for col in features + [target]:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Save encoders\n",
    "joblib.dump(label_encoders, 'label_encoders.pkl')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Save scaler\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "print(\"Data preprocessing complete. Encoders and scaler saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the SVM model\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(svm_model, 'svm_model_mbkm.pkl')\n",
    "\n",
    "print(\"Model training complete. Model saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the SVM model\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nAccuracy Score:\")\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import joblib\n",
    "\n",
    "# Load the dummy test data\n",
    "test_data_path = 'test.xlsx'  # Update with your file path\n",
    "test_data = pd.read_excel(test_data_path)\n",
    "\n",
    "# Extract original data for later combination\n",
    "original_test_data = test_data[['nama', 'nim', 'jurusan', 'status_kemahasiswaan']].copy()\n",
    "\n",
    "# Drop columns that are not features\n",
    "test_data = test_data.drop(columns=['nama', 'nim', 'jurusan'])\n",
    "\n",
    "# Convert all values in the columns to strings to handle mixed types\n",
    "test_data = test_data.astype(str)\n",
    "\n",
    "# Load encoders and scaler\n",
    "label_encoders = joblib.load('label_encoders.pkl')  # Update with your file path\n",
    "scaler = joblib.load('scaler.pkl')  # Update with your file path\n",
    "\n",
    "# Encode categorical variables using the same label encoders used in training\n",
    "encoded_test_data = test_data.copy()\n",
    "for col in encoded_test_data.columns:\n",
    "    if col in label_encoders:\n",
    "        le = label_encoders[col]\n",
    "        # Handle unseen labels by replacing with the most common class or a specific class\n",
    "        encoded_test_data[col] = encoded_test_data[col].apply(\n",
    "            lambda x: le.transform([x])[0] if x in le.classes_ else le.transform([le.classes_[0]])[0]\n",
    "        )\n",
    "\n",
    "# Separate data into detected and undetected\n",
    "detected_data_mask = encoded_test_data.apply(lambda x: x != 'Tidak Terdeteksi').all(axis=1)\n",
    "undetected_data_mask = ~detected_data_mask\n",
    "\n",
    "detected_test_data = encoded_test_data[detected_data_mask]\n",
    "undetected_test_data = encoded_test_data[undetected_data_mask]\n",
    "\n",
    "# Ensure all necessary features are present in detected test data\n",
    "for feature in scaler.feature_names_in_:\n",
    "    if feature not in detected_test_data.columns:\n",
    "        detected_test_data[feature] = 0\n",
    "\n",
    "# Reorder columns to match the order used in training\n",
    "detected_test_data = detected_test_data[scaler.feature_names_in_]\n",
    "\n",
    "# Normalize the detected data using the same scaler used in training\n",
    "if not detected_test_data.empty:\n",
    "    detected_test_data_scaled = scaler.transform(detected_test_data)\n",
    "    # Load the trained model\n",
    "    model_filename = 'svm_model_mbkm.pkl'  # Update with your file path\n",
    "    svm_model = joblib.load(model_filename)\n",
    "    # Make predictions\n",
    "    predictions = svm_model.predict(detected_test_data_scaled)\n",
    "\n",
    "    # Print SVM predictions\n",
    "    # print(\"SVM Predictions:\", predictions)\n",
    "\n",
    "    detected_test_data['lolos_mbkm'] = predictions\n",
    "    # Decode the predictions to original labels\n",
    "    detected_test_data['lolos_mbkm'] = detected_test_data['lolos_mbkm'].apply(lambda x: 'Lolos' if x == 1 else 'Tidak Lolos')\n",
    "\n",
    "# Add 'Tidak Terdeteksi' label to undetected data``\n",
    "undetected_test_data['lolos_mbkm'] = 'Tidak Terdeteksi'\n",
    "\n",
    "# Combine detected and undetected data\n",
    "combined_data = pd.concat([detected_test_data, undetected_test_data], axis=0)\n",
    "\n",
    "# Combine with original data for output\n",
    "output_data = pd.concat([original_test_data.reset_index(drop=True), combined_data['lolos_mbkm'].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Display the results\n",
    "display(output_data.head())\n",
    "\n",
    "# Save the test data with predictions\n",
    "test_data_with_predictions_path = 'hasil.xlsx'  # Update with your file path\n",
    "output_data.to_excel(test_data_with_predictions_path, index=False)\n",
    "\n",
    "print(f\"Predictions saved to {test_data_with_predictions_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the results data\n",
    "output_data_path = 'hasil.xlsx'\n",
    "output_data = pd.read_excel(output_data_path)\n",
    "\n",
    "# Load the original test data\n",
    "original_test_data_path = 'test.xlsx'\n",
    "original_test_data = pd.read_excel(original_test_data_path)\n",
    "\n",
    "# Display the first few rows of the output data\n",
    "display(output_data.head())\n",
    "\n",
    "# List to store skipped plots\n",
    "skipped_plots = []\n",
    "\n",
    "# Function to plot the count of categories\n",
    "def plot_count(data, column, title):\n",
    "    try:\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        category_mapping = {category: i for i, category in enumerate(data[column].unique(), start=1)}\n",
    "        data['category_number'] = data[column].map(category_mapping)\n",
    "        ax = sns.countplot(x='category_number', data=data)\n",
    "        plt.title(title)\n",
    "        \n",
    "        # Create a custom legend\n",
    "        handles = [plt.Line2D([0], [0], marker='o', color=ax.patches[i].get_facecolor(), linestyle='') \n",
    "                   for i, category in enumerate(category_mapping)]\n",
    "        labels = [f\"{num}: {cat}\" for cat, num in category_mapping.items()]\n",
    "        \n",
    "        plt.legend(handles=handles, title=column, loc='center left', bbox_to_anchor=(1, 0.5), labels=labels)\n",
    "        plt.xlabel('Category Number')\n",
    "        plt.show()\n",
    "\n",
    "        # Display the table\n",
    "        if column in data.columns:\n",
    "            count_data = data[[column, 'lolos_mbkm']].value_counts().unstack().fillna(0)\n",
    "            display(count_data)\n",
    "        else:\n",
    "            raise ValueError(f\"No data available for {column}\")\n",
    "    except Exception as e:\n",
    "        skipped_plots.append(f\"{title}: {e}\")\n",
    "\n",
    "# Add missing columns from the original data if necessary\n",
    "columns_to_add = ['status_kemahasiswaan', 'jenis_kelamin']\n",
    "for col in columns_to_add:\n",
    "    if col not in output_data.columns and col in original_test_data.columns:\n",
    "        output_data[col] = original_test_data[col]\n",
    "\n",
    "# Plot the total counts\n",
    "print(\"Total Lolos MBKM\")\n",
    "plot_count(output_data, 'lolos_mbkm', 'Total Lolos MBKM')\n",
    "\n",
    "# Plot the counts by gender (if available)\n",
    "if 'jenis_kelamin' in output_data.columns:\n",
    "    print(\"Lolos MBKM Berdasarkan Jenis Kelamin\")\n",
    "    plot_count(output_data, 'jenis_kelamin', 'Lolos MBKM Berdasarkan Jenis Kelamin')\n",
    "\n",
    "# Plot the counts by jurusan\n",
    "print(\"Lolos MBKM Berdasarkan Jurusan\")\n",
    "plot_count(output_data, 'jurusan', 'Lolos MBKM Berdasarkan Jurusan')\n",
    "\n",
    "# Plot the counts by status kemahasiswaan (if available)\n",
    "if 'status_kemahasiswaan' in output_data.columns:\n",
    "    print(\"Lolos MBKM Berdasarkan Status Kemahasiswaan\")\n",
    "    plot_count(output_data, 'status_kemahasiswaan', 'Lolos MBKM Berdasarkan Status Kemahasiswaan')\n",
    "\n",
    "# Plot the counts of Lolos and Tidak Lolos by gender (if gender data available)\n",
    "if 'jenis_kelamin' in output_data.columns:\n",
    "    print(\"Lolos/Tidak Lolos Berdasarkan Jenis Kelamin\")\n",
    "    try:\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        category_mapping = {category: i for i, category in enumerate(output_data['jenis_kelamin'].unique(), start=1)}\n",
    "        output_data['category_number'] = output_data['jenis_kelamin'].map(category_mapping)\n",
    "        ax = sns.countplot(x='category_number', hue='lolos_mbkm', data=output_data)\n",
    "        plt.title('Lolos/Tidak Lolos Berdasarkan Jenis Kelamin')\n",
    "        \n",
    "        # Create a custom legend\n",
    "        handles = [plt.Line2D([0], [0], marker='o', color=ax.patches[i].get_facecolor(), linestyle='') \n",
    "                   for i, category in enumerate(category_mapping)]\n",
    "        labels = [f\"{num}: {cat}\" for cat, num in category_mapping.items()]\n",
    "        \n",
    "        plt.legend(handles=handles, title='Jenis Kelamin', loc='center left', bbox_to_anchor=(1, 0.5), labels=labels)\n",
    "        plt.xlabel('Category Number')\n",
    "        plt.show()\n",
    "        \n",
    "        count_data = output_data[['jenis_kelamin', 'lolos_mbkm']].value_counts().unstack().fillna(0)\n",
    "        display(count_data)\n",
    "    except Exception as e:\n",
    "        skipped_plots.append(f\"Lolos/Tidak Lolos Berdasarkan Jenis Kelamin: {e}\")\n",
    "\n",
    "# Plot the counts of Lolos and Tidak Lolos by jurusan\n",
    "print(\"Lolos/Tidak Lolos Berdasarkan Jurusan\")\n",
    "try:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    category_mapping = {category: i for i, category in enumerate(output_data['jurusan'].unique(), start=1)}\n",
    "    output_data['category_number'] = output_data['jurusan'].map(category_mapping)\n",
    "    ax = sns.countplot(x='category_number', hue='lolos_mbkm', data=output_data)\n",
    "    plt.title('Lolos/Tidak Lolos Berdasarkan Jurusan')\n",
    "    \n",
    "    # Create a custom legend\n",
    "    handles = [plt.Line2D([0], [0], marker='o', color=ax.patches[i].get_facecolor(), linestyle='') \n",
    "               for i, category in enumerate(category_mapping)]\n",
    "    labels = [f\"{num}: {cat}\" for cat, num in category_mapping.items()]\n",
    "    \n",
    "    plt.legend(handles=handles, title='Jurusan', loc='center left', bbox_to_anchor=(1, 0.5), labels=labels)\n",
    "    plt.xlabel('Category Number')\n",
    "    plt.show()\n",
    "    \n",
    "    count_data = output_data[['jurusan', 'lolos_mbkm']].value_counts().unstack().fillna(0)\n",
    "    display(count_data)\n",
    "except Exception as e:\n",
    "    skipped_plots.append(f\"Lolos/Tidak Lolos Berdasarkan Jurusan: {e}\")\n",
    "\n",
    "# Print skipped plots\n",
    "if skipped_plots:\n",
    "    print(\"\\nSkipped Plots:\")\n",
    "    for plot in skipped_plots:\n",
    "        print(plot)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
